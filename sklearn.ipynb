{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zwYX07xsA7sp",
        "outputId": "47fa8bb6-6b41-4fe7-9969-e37428ae7876"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 58.1M    0 58.1M    0     0  40.4M      0 --:--:--  0:00:01 --:--:-- 40.4M\n"
          ]
        }
      ],
      "source": [
        "!curl -LO \"https://archive.ics.uci.edu/static/public/240/human+activity+recognition+using+smartphones.zip\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip human+activity+recognition+using+smartphones.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4bVSomCBDYl",
        "outputId": "e8b9d5b4-1144-46b6-f496-c44ccffd372d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  human+activity+recognition+using+smartphones.zip\n",
            "replace UCI HAR Dataset.names? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -qq \"UCI HAR Dataset.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cc1LNmgkBOTr",
        "outputId": "f072610f-63a3-4840-aba8-acc244202177"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "replace UCI HAR Dataset/.DS_Store? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, log_loss\n",
        "\n",
        "\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.layers import LSTM, Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "\n",
        "# get the features from the file features.txt\n",
        "features = list()\n",
        "with open('UCI HAR Dataset/features.txt') as f:\n",
        "    features = [line.split()[1] for line in f.readlines()]\n",
        "print('No of Features: {}'.format(len(features)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bhcyd1l8BRX4",
        "outputId": "2e39bd88-26fc-4654-b6a9-3718e6992748"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No of Features: 561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## get the data from txt files to pandas dataffame\n",
        "# training data\n",
        "X_train = pd.read_csv('UCI HAR Dataset/train/X_train.txt', delim_whitespace=True, header=None)\n",
        "X_train.columns = features\n",
        "X_train['Activity'] = pd.read_csv('UCI HAR Dataset/train/y_train.txt', names=['Activity'])\n",
        "\n",
        "# training labels\n",
        "y_train_subject = pd.read_csv('UCI HAR Dataset/train/subject_train.txt', names=['subject'])\n",
        "X_train['subject'] = y_train_subject"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dRiaw7WXB7e9",
        "outputId": "546afa30-b34b-4467-cbdb-040b4b67b025"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-2-76fd5a8203ee>:3: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  X_train = pd.read_csv('UCI HAR Dataset/train/X_train.txt', delim_whitespace=True, header=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test data\n",
        "X_test = pd.read_csv('UCI HAR Dataset/test/X_test.txt', delim_whitespace=True, header=None)\n",
        "X_test.columns = features\n",
        "X_test['Activity'] = pd.read_csv('UCI HAR Dataset/test/y_test.txt', names=['Activity'])\n",
        "\n",
        "# test labels\n",
        "y_test_subject = pd.read_csv('UCI HAR Dataset/test/subject_test.txt', names=['Activity'])\n",
        "X_test['subject'] = y_test_subject"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kosfgpeLB9bL",
        "outputId": "c25461a9-08b6-4032-b584-4c8da8cd9932"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-3-abe73ffddcd5>:2: FutureWarning: The 'delim_whitespace' keyword in pd.read_csv is deprecated and will be removed in a future version. Use ``sep='\\s+'`` instead\n",
            "  X_test = pd.read_csv('UCI HAR Dataset/test/X_test.txt', delim_whitespace=True, header=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Combine both train and test data\n",
        "all_X_data = pd.concat([X_train, X_test], axis=0)\n",
        "all_X_data = all_X_data.reset_index(drop=True)\n",
        "\n",
        "all_y_data = pd.concat([y_train_subject, y_test_subject], axis=0)\n",
        "all_y_data = all_y_data.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "BWkRVJcTCDX1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the test train data\n",
        "subject_train, subject_test = train_test_split(all_X_data, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "4Mzu0nGcCFKW"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = subject_train['subject']\n",
        "X_train = subject_train.drop('subject', axis=1)\n",
        "\n",
        "y_test = subject_test['subject']\n",
        "X_test = subject_test.drop('subject', axis=1)"
      ],
      "metadata": {
        "id": "gia3xLLgCIuN"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "\n",
        "\n",
        "test_accuracy = lr_model.score(X_test, y_test)\n",
        "test_loss = log_loss(y_test, sgd_clf.predict_proba(X_test))\n",
        "print (\"Accuracy and Loss for test data using LogisticRegression is {} and {}\".format(test_accuracy, test_loss))\n",
        "\n",
        "# Evaluate the model\n",
        "train_accuracy = lr_model.score(X_train, y_train)\n",
        "train_loss = log_loss(y_train, sgd_clf.predict_proba(X_train))\n",
        "print (\"Accuracy and Loss for training data using LogisticRegression is {} and {}\".format(train_accuracy, train_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4pdxZClyCMU2",
        "outputId": "4bb3bbc4-80d3-472d-a42d-a040fad80d18"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy and Loss for test data using LogisticRegression is 0.6810679611650485 and 12.912178337473698\n",
            "Accuracy and Loss for training data using LogisticRegression is 0.8581138487680544 and 9.817336993659847\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# Create an SGDClassifier instance\n",
        "sgd_clf = SGDClassifier(loss='log_loss', max_iter=1000, tol=1e-3, random_state=42)\n",
        "\n",
        "# Fit the model\n",
        "sgd_clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = sgd_clf.predict(X_test)\n",
        "\n",
        "# Evaluate the model\n",
        "accuracy = sgd_clf.score(X_test, y_test)\n",
        "loss = log_loss(y_test, sgd_clf.predict_proba(X_test))\n",
        "print (\"Accuracy and Loss using LogisticRegression is {} and {}\".format(accuracy, loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "64cs6-B9DTtQ",
        "outputId": "f6713bc3-5343-4672-f514-63be573d8c1a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy and Loss using LogisticRegression is 0.5597087378640777 and 12.912178337473698\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_accuracy = sgd_clf.score(X_train, y_train)\n",
        "train_loss = log_loss(y_train, sgd_clf.predict_proba(X_train))\n",
        "print (\"Accuracy and Loss for training data using LogisticRegression is {} and {}\".format(train_accuracy, train_loss))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RYQoxRw8IQpg",
        "outputId": "ba6eee9b-3039-4e01-f55e-7765b0e85c0a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy and Loss for training data using LogisticRegression is 0.6585750697900231 and 9.817336993659847\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BKmPS9zQh054"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}